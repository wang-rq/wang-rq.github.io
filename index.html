<!DOCTYPE html>
<!--
    Plain-Academic by Vasilios Mavroudis
    Released under the Simplified BSD License/FreeBSD (2-clause) License.
    https://github.com/mavroudisv/plain-academic
-->


<html lang="en">

<head>

  <title>Ruoqi Wang</title>
  <link rel="shortcut icon" type="image/jpg" href="imgs/icon.jpg" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
  <link href='https://fonts.googleapis.com/css?family=Oswald:700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Philosopher' rel='stylesheet'>


</head>

<body style="font-family: Georgia, serif; font-size: 1.5em; margin-bottom: 40px">

  <!-- Navigation -->
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
          data-target="#bs-example-navbar-collapse-1">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
      </div>

      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
        <ul class="nav navbar-nav">
          <li><a href="">Home</a></li>
          <li><a href="files/cv.pdf" target="_blank">CV</a></li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Page Content -->

  <div class="container" style="margin-top: 100px; margin-bottom: 100px;">

    <div class="row">

      <!-- Entries Column -->
      <div class="col-md-10">

        <!-- Main Image -->
        <div class="col-md-3">
          <img class="img-responsive" width="150px" src="imgs/photo.jpg">

        </div>



        <div class="col-md-6">
          <div style="font-family: Philosopher, sans-serif; font-size: 30px;"><b>Ruoqi Wang (王若琪)</b></div><br>

          Senior Student <br>
          Sun Yat-sen University<br>
          Guangzhou, China<br>
          <p style="font-family: Philosopher, sans-serif;"><a href="mailto:wangrq29@mail2.sysu.edu.cn"><b>Email:
                wangrq29@mail2.sysu.edu.cn</b></a> <br>
            <br>
            <b>Curriculum Vitae: <a href="files/cv.pdf" target="_blank">[CV]</a></b>
          </p>
        </div>
      </div>

      <!-- Biography -->
      <div class="col-md-10">
        <h2 id="Biography" style="font-family: Philosopher, sans-serif; ">Biography</h2>

        I am a senior student at Sun Yat-sen University. I am majoring in Computer Science and Technology and will
        receive a bachelor's degree in June 2022.
        Also, I am a student intern in Machine Perception Laboratory, SYSU, advised by <a href="http://www.scholat.com/wuhejun" target="_blank">Dr. Hejun Wu</a>. 
        I'm going to start my PhD study in September 2022 in HKUST(GZ) and I'm eager to hear any useful suggestions.

      </div>

      <!-- Education -->
      <div class="col-md-10">
        <h2 id="Education" style="font-family: Philosopher, sans-serif;">Education</h2>

        <strong>Sun Yat-sen University (SYSU), &nbsp;&nbsp;&nbsp; B.Eng. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Sep. 2018 ~
          Jun. 2022 (expected)]</strong><br />
        <ul>
          <li> Major: Computer Science and Technology, School of Computer Science and Engineering. </li>
          <li> Awards and Honors:<br>
              &nbsp;&nbsp;&nbsp;-&nbsp;&nbsp;&nbsp;Academic Excellence Scholarship, Sun Yat-sen University, 2020 <br>
              &nbsp;&nbsp;&nbsp;-&nbsp;&nbsp;&nbsp;Student Elite Representative, School of Computer Science and Engineering, Sun Yat-sen University, 2021</li>
              &nbsp;&nbsp;&nbsp;-&nbsp;&nbsp;&nbsp;Academic Excellence Scholarship, Sun Yat-sen University, 2021 <br>
        </ul>


      </div>




      <div id="paper">
        
        <div class="col-md-10">
          <h2 id="Research Papers" style="font-family: Philosopher, sans-serif;">Research Papers</h2>
        </div>

        <div class="col-md-10"><h4 style="text-align: center">Accepted</h4></div>
        <div class="col-md-10">
          <div class="col-md-3"><img class="img" src="imgs/SeTranSurv.jpg" width="200" height="95"
              style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
          <div class="col-md-9">
            <li class="paper" words="hh">Ziwang Huang, Hua Chai, <u>Ruoqi Wang</u>, Haitao Wang, Yuedong Yang and Hejun
              Wu,
              "<a href="files/paper_SeTranSurv.pdf" target="_blank">Integration of Patch Features through
                Self-Supervised Learning and Transformer for Survival Analysis on Whole Slide Images</a>",
              <i>International Conference on Medical Image Computing and Computer-Assisted Intervention</i> (<b>MICCAI</b>), pages 561–570, 2021
            </li>
          </div>
        </div>

        <div class="col-md-10"><br></div>

        <div class="col-md-10">
          <div class="col-md-3"><img class="img" src="imgs/AMMA.jpg" width="200" height="95"
              style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
          <div class="col-md-9">
            <li class="paper" words="hh"><u>Ruoqi Wang</u>, Ziwang Huang, Haitao Wang, Hejun Wu,
              "<a href="http://arxiv.org/abs/2108.12565" target="_blank">AMMASurv: Asymmetrical Multi-Modal Attention
                for Accurate Survival Analysis with Whole Slide Images and Gene Expression Data</a>",
              <i>IEEE International Conference on Bioinformatics and Biomedicine </i> (<b>IEEE BIBM</b>), pages 757-760,
              2021
            </li>
          </div>
        </div>
          

        <div class="col-md-10"><br></div>

        <div class="col-md-10"><h4 style="text-align: center">Under Review</h4></div>

        <div class="col-md-10"><br></div>

        <div class="col-md-10">
          <div class="col-md-3"><img class="img" src="imgs/crack.jpg" width="200" height="95"
              style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
          <div class="col-md-9">
            <li class="paper" words="hh">Haitao Wang, Hejun Wu, <u>Ruoqi Wang</u>, Ziwang Huang,
              "Deep Discriminative Feature Learning for Concrete Surface Damage Classification", under review, 2022
            </li>
          </div>
        </div>

        <div class="col-md-10"><br></div>

        <div class="col-md-10">
          <div class="col-md-3"><img class="img" src="imgs/dcrl.jpg" width="200" height="95"
              style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
          <div class="col-md-9">
            <li class="paper" words="hh">Haitao Wang, Yongqiang You, Hejun Wu, <u>Ruoqi Wang</u>,
              "Discrete Contrastive Representation Learning for Reinforcement Learning", under review, 2022
            </li>
          </div>
        </div>

        <div class="col-md-10"><br></div>

        <!-- Experience -->
        <div class="col-md-10">
          <h2 id="Research Projects" style="font-family: Philosopher, sans-serif;">Research Projects</h2>
          <h4 style="text-align: center">Artificial Intelligence in Healthcare</h4>
          <ul>
            <li> <b> Asymmetrical multi-modal survival analysis using medical images and structured data. [May. 2021 ~ Aug. 2021] </b>
              <br>
              Machine Perception Laboratory, SYSU, Guangzhou, China<br>
              <div class="col-md-12"><br></div>
              <div class="col-md-12">
              <div class="col-md-3"><img class="img" src="imgs/AMMA_res_1.jpg" width="200" height="120"
                  style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
              <div class="col-md-3"><img class="img" src="imgs/AMMA_res_2.jpg" width="200" height="120"
                  style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
              <div class="col-md-4"><img class="img" src="imgs/AMMA_res_3.jpg" width="260" height="120"
                  style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
              </div>
              <div class="col-md-12"><br></div>
              My contributions:
              <ul>
                <li> I independently designed an asymmetrical multi-modal attention mechanism (AMMA) to generate more flexible joint
                  representation of medical images and structured data. </li>
                <li> Different from previous works, AMMA can effectively utilize the intrinsic information within every modality and flexibly
                  adapt to the modalities of different importance. </li>
                <li> I designed and conducted various experiments to verify the effectiveness of the new model. On public datasets from
                  TCGA, the results of the proposed method are 5%-6% higher (C-index) than other SOTA methods. </li>
                <li> The article “<a href="http://arxiv.org/abs/2108.12565" target="_blank"><u>AMMASurv: Asymmetrical Multi-Modal Attention for Accurate Survival Analysis with Whole Slide Images and
                  Gene Expression Data</u></a>” was accepted as a short paper by IEEE BIBM.</li>
              </ul>
            </li>



            <div class="col-md-12"><br></div>

            <li> <b>Integration of Patch Features of Whole Slide Images through Self-Supervised Learning and Transformer for Survival Analysis. [Dec. 2020 ~ Mar. 2021]</b> <br>
              Machine Perception Laboratory, SYSU, Guangzhou, China<br>
              <div class="col-md-12"><br></div>
              <div class="col-md-12">
              <div class="col-md-7"><img class="img" src="imgs/SeTran_res_1.jpg" width="500" height="120"
                  style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
              <div class="col-md-4"><img class="img" src="imgs/SeTran_res_2.jpg" width="220" height="120"
                  style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
              </div>
              <div class="col-md-12"><br></div>
              My contributions:
              <ul>
                <li> I conducted experiments on the influence of self-supervised learning for extracting the features of whole slide images (WSIs) and researched the effect of positional embedding of WSI patches. </li>
                <li> The approach with self-supervised learning and position embedding outperformed the previous best approach by an average of 3% (C-index) in survival prediction on three datasets. </li>
                <li> The article “<a href="files/paper_SeTranSurv.pdf" target="_blank"><u>Integration of Patch Features through Self-Supervised Learning and Transformer for Survival Analysis on Whole Slide Images</u></a>” was accepted by MICCAI 2021.</li>
              </ul>
            </li>


            <div class="col-md-12"><br></div>

            <li> <b>The effect of surgery and drug treatment on the visual field progression of different glaucoma
                patients and glaucoma patients with comorbidities.[Dec. 2020 ~ Mar. 2021]</b> <br>
              Zhongshan Ophthalmic Center, Guangzhou, China<br>
              My contributions:
              <ul>
                <li> I designed an efficient sample matching method based on the Levenshtein distance algorithm to solve the problems of inaccurate and incomplete information in the original medical dataset.</li>
                <li> The proposed method increased the number of effective samples by 30%, facilitating subsequent experiments.</li>
              </ul>
            </li>

            <div class="col-md-12"><br></div>

            <li> <b>Machine disease diagnosis on small and unbalanced datasets with multi-modal data.[Nov. 2020 ~
                Dec. 2020]</b> <br>
              Machine Perception Laboratory, SYSU, Guangzhou, China<br>
              My contributions:
              <ul>
                <li> I used multi-modal data (clinical data and omics data of patients with nasopharyngeal carcinoma) to get better joint
                  representations for classification.</li>
                <li> I proved the complementarity between data from two modalities. </li>
                <li> I studied the application of machine learning methods on small and uneven datasets.</li>
                <li> Cooperated with SYSU Cancer Center (<a href="https://www.sysucc.org.cn/"
                    target="_blank"><u>SYSUCC</u></a>).
              </ul>
            </li>
            <br>
          </ul>

          <div class="col-md-12"><br></div>

          <h4 style="text-align: center">Artificial Intelligence in Industry</h4>
          <ul>
            <li> <b>Deep discriminative feature learning on concrete surface images. [Jul. 2021 ~ Sep.
                2021] </b><br>
              Machine Perception Laboratory, SYSU, Guangzhou, China<br>
              <div class="col-md-12"><br></div>
              <div class="col-md-12">
                <div class="col-md-7"><img class="img" src="imgs/crack_res_1.jpg" width="500" height="120"
                    style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
                <div class="col-md-3"><img class="img" src="imgs/crack.jpg" width="220" height="120"
                    style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
              </div>
              <div class="col-md-12"><br></div>
              My contributions:
              <ul>
                <li> I participated in researching a novel end-to-end framework named Deep Discriminative Feature Learning (DDFL) based on Collective Matrix Factorization (CMF) and Vision Transformer (ViT) to extract and select discriminative features of crack images.</li>
                <li> The learning framework integrates the deep feature learning and feature selection so that more discriminative representation can be learned for crack classification.</li>
                <li> The article “Deep Discriminative Feature Learning for Concrete Surface Damage Classification” was submitted to IEEE TII.</li>
              </ul>
            </li>
          </ul>

            <div class="col-md-12"><br></div>

          <h4 style="text-align: center">Smart City</h4>
          <ul>
            <li> <b>Smart balanced delivery task scheduling based on TSP solver. [Jul. 2021 ~ Aug. 2021] </b><br>
              Machine Perception Laboratory, SYSU, Guangzhou, China<br>
              <div class="col-md-12"><br></div>
              <div class="col-md-12">
                <div class="col-md-3"><img class="img" src="imgs/gcn_res_1.jpg" width="200" height="120"
                    style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
                <div class="col-md-3"><img class="img" src="imgs/gcn_res_2.jpg" width="200" height="120"
                    style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
                <div class="col-md-4"><img class="img" src="imgs/gcn_res_3.jpg" width="260" height="120"
                    style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
              </div>
              <div class="col-md-12"><br></div>
              My contributions:
              <ul>
                <li> I optimized one of the proposed algorithms by reducing loops and superimpose distance and time matrices, making
                  the computational complexity become 1/2 of the original method.</li> 
                <li> I re-implemented a baseline method <a href="https://github.com/wang-rq/GCN-NPEC"><u>[Code: GCN-NPEC]</u></a>. </li>
              </ul>
            </li>



          </ul>
          </li>
          <br>


        </div>


        <!-- Teaching -->
        <div class="col-md-10">
          <h2 id="Teaching" style="font-family: Philosopher, sans-serif;">Teaching</h2>
          I have given two lectures for graduate students in the deep learning course offered by our laboratory in May
          2021.
          The two lectures are about VAE (Variational AutoEncoder) and GAN (Generative Adversarial Nets) respectively.
          <div class="col-md-12"><br></div>
          <div class="col-md-12">
            <div class="col-md-3"><img class="img" src="imgs/vae.jpg" width="150" height="100"
                style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
            <div class="col-md-3"><img class="img" src="imgs/gan.jpg" width="150" height="100"
                style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
          </div>
          <div class="col-md-12"><br></div>
          <br>
          My slides and prevues are as follows.
          <ul>
            <li>VAE: <a href="files/VAE_wrq.pdf" target="_blank"> <u>[Slide_VAE]</u></a>, <a
                href="https://www.bilibili.com/video/BV16f4y1N7ck" target="_blank"> <u>[Prevue_VAE]</u></a></li>
            <li>GAN: <a href="files/GAN_wrq.pdf" target="_blank"> <u>[Slide_GAN]</u></a>, <a
                href="https://www.bilibili.com/video/BV1kP4y1p7hQ" target="_blank"> <u>[Prevue_GAN]</u></a></li>
          </ul>
        </div>




        <!-- Hobbies -->
        <div class="col-md-10">
          <h2 id="Hobbies" style="font-family: Philosopher, sans-serif;">Hobbies</h2>
          <div class="col-md-12">
            <div class="col-md-1"><img class="img" src="imgs/sport0.png" width="25" height="25"
              style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
            <div class="col-md-1"><img class="img" src="imgs/sport2.jpg" width="25" height="25"
                style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
            <div class="col-md-1"><img class="img" src="imgs/sport3.jpg" width="25" height="25"
                style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
            <div class="col-md-1"><img class="img" src="imgs/sport1.jpg" width="25" height="25"
              style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
            <div class="col-md-1"><img class="img" src="imgs/sport4.jpg" width="25" height="25"
              style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
          </div>
          <div class="col-md-12"><br></div>
          I like sports. I am crazy about tennis. Also, I enjoy ping-pong, swimming and jogging. Also, I have participated in some sports games:
          <ul>
            <li>Gold medal in long jump, CSE sports games, 2019.</li>
            <li>Bronze medal in the 1500 metres, CSE sports games, 2019.</li>
            <li>Bronze medal in the 100 metres, CSE sports games, 2020.</li>
            <li>Champion of the SDCS student union basketball game, 2018.</li>
            <li>Top 16 in the university table tennis game, 2021.</li>
            <li>Top 8 in the university team table tennis game, 2021.</li>
          </ul>
          I am looking for more friends who have the same hobbies as me.
          If you like these sports, please contact me and we can exercise together!

          
        </div>

      </div>

    </div>
    <!-- /.container -->

    <!-- Other people may like it too! -->
    <a style="color:#b5bec9;font-size:0.8em; float:right;"
      href="https://github.com/mavroudisv/plain-academic">Template</a>

</body>

</html>