<!DOCTYPE html>
<!--
    Plain-Academic by Vasilios Mavroudis
    Released under the Simplified BSD License/FreeBSD (2-clause) License.
    https://github.com/mavroudisv/plain-academic
-->


<html lang="en">

<head>

  <title>Ruoqi Wang</title>
  <link rel="shortcut icon" type="image/jpg" href="imgs/icon.jpg" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
  <link href='https://fonts.googleapis.com/css?family=Oswald:700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Philosopher' rel='stylesheet'>


</head>

<body style="font-family: Georgia, serif; font-size: 1.5em; margin-bottom: 40px">

  <!-- Navigation -->
  <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
          data-target="#bs-example-navbar-collapse-1">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
      </div>

      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
        <ul class="nav navbar-nav">
          <li><a href="">Home</a></li>
          <li><a href="files/CV.pdf" target="_blank">CV</a></li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Page Content -->

  <div class="container" style="margin-top: 100px; margin-bottom: 100px;">

    <div class="row">

      <!-- Entries Column -->
      <div class="col-md-10">

        <!-- Main Image -->
        <div class="col-md-3">
          <img class="img-responsive" width="150px" src="imgs/photo.jpg">

        </div>



        <div class="col-md-6">
          <div style="font-family: Philosopher, sans-serif; font-size: 30px;"><b>Ruoqi Wang (王若琪)</b></div><br>

          Senior Student <br>
          Sun Yat-sen University<br>
          Guangzhou, China<br>
          <p style="font-family: Philosopher, sans-serif;"><a href="mailto:wangrq29@mail2.sysu.edu.cn"><b>Email:
                wangrq29@mail2.sysu.edu.cn</b></a> <br>
            <br>
            <b>Curriculum Vitae: <a href="files/CV.pdf" target="_blank">[CV]</a></b>
          </p>
        </div>
      </div>

      <!-- Biography -->
      <div class="col-md-10">
        <h2 id="Biography" style="font-family: Philosopher, sans-serif; ">Biography</h2>

        I am a senior student at Sun Yat-sen University. I am majoring in Computer Science and Technology and will
        receive a bachelor's degree in June 2022.
        Also, I am a student intern in Machine Perception Laboratory, SYSU.
        My research interest mainly lies in AI in healthcare, machine learning, deep learning and computer vision.
        <font color="red"> I am looking for a Ph.D. research position and I am eager to hear any useful suggestions and
          offers. </font>

      </div>

      <!-- Education -->
      <div class="col-md-10">
        <h2 id="Education" style="font-family: Philosopher, sans-serif;">Education</h2>

        <strong>Sun Yat-sen University (SYSU), &nbsp;&nbsp;&nbsp; B.Eng. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Sep. 2018 ~
          Jun. 2022 (expected)]</strong><br />
        <ul>
          <li> Major: Computer Science and Technology, School of Computer Science and Engineering. </li>
          <li> Weighted Average Grade: 89/100 (GPA: 3.8/4.0)<br>
            &nbsp;&nbsp;&nbsp;-&nbsp;&nbsp;&nbsp;Freshman Year: 85/100,&nbsp;&nbsp;&nbsp; Sophomore Year:
            91/100,&nbsp;&nbsp;&nbsp; Junior Year: 91/100</li>
          <li> Awards<br>
              &nbsp;&nbsp;&nbsp;-&nbsp;&nbsp;&nbsp;Academic Excellence Scholarship, Sun Yat-sen University, 2020 <br>
              &nbsp;&nbsp;&nbsp;-&nbsp;&nbsp;&nbsp;Student Elite Representative, School of Computer Science and Engineering, Sun Yat-sen University, 2021</li>
        </ul>


      </div>


      <!-- Publications -->

      <div id="pubs">

        <div class="col-md-10">
          <h2 id="Publications" style="font-family: Philosopher, sans-serif;">Publications</h2>
          <div class="col-md-3"><img class="img" src="imgs/AMMA.jpg" width="200" height="95"
              style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
          <div class="col-md-9">
            <li class="paper" words="hh"><u>Ruoqi Wang</u>, Ziwang Huang, Haitao Wang, Hejun Wu,
              "<a href="http://arxiv.org/abs/2108.12565" target="_blank">AMMASurv: Asymmetrical Multi-Modal Attention
                for Accurate Survival Analysis with Whole Slide Images and Gene Expression Data</a>",
              <i>IEEE International Conference on Bioinformatics and Biomedicine </i> (<b>IEEE BIBM</b>), under review,
              2021
            </li>
          </div>
        </div>

        <div class="col-md-10"><br></div>

        <div class="col-md-10">
          <div class="col-md-3"><img class="img" src="imgs/SeTranSurv.jpg" width="200" height="95"
              style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
          <div class="col-md-9">
            <li class="paper" words="hh">Ziwang Huang, Hua Chai, <u>Ruoqi Wang</u>, Haitao Wang, Yuedong Yang and Hejun
              Wu,
              "<a href="files/paper_SeTranSurv.pdf" target="_blank">Integration of Patch Features through
                Self-Supervised Learning and Transformer for Survival Analysis on Whole Slide Images</a>",
              <i>Medical Image Computing and Computer Assisted Intervention</i> (<b>MICCAI</b>), <b>accepted</b>, 2021
            </li>
          </div>
        </div>

        <div class="col-md-10"><br></div>

        <div class="col-md-10">
          <div class="col-md-3"><img class="img" src="imgs/crack.jpg" width="200" height="95"
              style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
          <div class="col-md-9">
            <li class="paper" words="hh">Haitao Wang, Hejun Wu, <u>Ruoqi Wang</u>, Ziwang Huang,
              "Deep Discriminative Feature Learning for Concrete Surface Damage Classification",
              <i>IEEE Transactions on Industrial Informatics </i> (<b>IEEE TII</b>), under review, 2021
            </li>
          </div>
        </div>

        <div class="col-md-10"><br></div>

        <div class="col-md-10">
          <div class="col-md-3"><img class="img" src="imgs/dcrl.jpg" width="200" height="95"
              style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
          <div class="col-md-9">
            <li class="paper" words="hh">Haitao Wang, Yongqiang You, Hejun Wu, <u>Ruoqi Wang</u>,
              "Discrete Contrastive Learning for Sample-Efficient Reinforcement Learning",
              <i>AAAI Conference on Artificial Intelligence </i> (<b>AAAI</b>), under review, 2022
            </li>
          </div>
        </div>

        <div class="col-md-10"><br></div>

        <!-- Experience -->
        <div class="col-md-10">
          <h2 id="Research Projects" style="font-family: Philosopher, sans-serif;">Research Projects</h2>
          <h4 style="text-align: center">Artificial Intelligence in Healthcare</h4>
          <ul>
            <li> <b> Asymmetrical multi-modal survival analysis using medical images and structured data. [May. 2021 ~ Aug. 2021] </b>
              <br>
              Machine Perception Laboratory, SYSU, Guangzhou, China<br>
              <div class="col-md-12"><br></div>
              <div class="col-md-12">
              <div class="col-md-3"><img class="img" src="imgs/AMMA_res_1.jpg" width="200" height="120"
                  style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
              <div class="col-md-3"><img class="img" src="imgs/AMMA_res_2.jpg" width="200" height="120"
                  style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
              <div class="col-md-4"><img class="img" src="imgs/AMMA_res_3.jpg" width="260" height="120"
                  style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
              </div>
              <div class="col-md-12"><br></div>
              My contributions:
              <ul>
                <li> I independently designed an asymmetrical multi-modal attention mechanism (AMMA) to generate more flexible joint
                  representation of medical images and structured data. </li>
                <li> Different from previous works, AMMA can effectively utilize the intrinsic information within every modality and flexibly
                  adapt to the modalities of different importance. </li>
                <li> I designed and conducted various experiments to verify the effectiveness of the new model. On public datasets from
                  TCGA, the results of the proposed method are 5%-6% higher (C-index) than other SOTA methods. </li>
                <li> The article “<a href="http://arxiv.org/abs/2108.12565" target="_blank"><u>AMMASurv: Asymmetrical Multi-Modal Attention for Accurate Survival Analysis with Whole Slide Images and
                  Gene Expression Data</u></a>” is submitted to IEEE BIBM.</li>
              </ul>
            </li>



            <div class="col-md-12"><br></div>

            <li> <b>Integration of Patch Features of Whole Slide Images through Self-Supervised Learning and Transformer for Survival Analysis. [Dec. 2020 ~ Mar. 2021]</b> <br>
              Machine Perception Laboratory, SYSU, Guangzhou, China<br>
              <div class="col-md-12"><br></div>
              <div class="col-md-12">
              <div class="col-md-7"><img class="img" src="imgs/SeTran_res_1.jpg" width="500" height="120"
                  style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
              <div class="col-md-4"><img class="img" src="imgs/SeTran_res_2.jpg" width="220" height="120"
                  style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
              </div>
              <div class="col-md-12"><br></div>
              My contributions:
              <ul>
                <li> I conducted experiments on the influence of self-supervised learning for extracting the features of whole slide images (WSIs) and researched the effect of positional embedding of WSI patches. </li>
                <li> The approach with self-supervised learning and position embedding outperformed the previous best approach by an average of 3% (C-index) in survival prediction on three datasets. </li>
                <li> The article “<a href="files/paper_SeTranSurv.pdf" target="_blank"><u>Integration of Patch Features through Self-Supervised Learning and Transformer for Survival Analysis on Whole Slide Images</u></a>” is accepted by MICCAI 2021.</li>
              </ul>
            </li>


            <div class="col-md-12"><br></div>

            <li> <b>The effect of surgery and drug treatment on the visual field progression of different glaucoma
                patients and glaucoma patients with comorbidities.[Dec. 2020 ~ Mar. 2021]</b> <br>
              Zhongshan Ophthalmic Center, Guangzhou, China<br>
              My contributions:
              <ul>
                <li> I designed an efficient sample matching method based on the Levenshtein distance algorithm to solve the problems of inaccurate and incomplete information in the original medical dataset.</li>
                <li> The proposed method increased the number of effective samples by 30%, facilitating subsequent experiments.</li>
                <li> The results are expected to be published in 2022. </li>
              </ul>
            </li>

            <div class="col-md-12"><br></div>

            <li> <b>Machine disease diagnosis on small and unbalanced datasets with multi-modal data.[Nov. 2020 ~
                Dec. 2020]</b> <br>
              Machine Perception Laboratory, SYSU, Guangzhou, China<br>
              My contributions:
              <ul>
                <li> I used multi-modal data (clinical data and omics data of patients with nasopharyngeal carcinoma) to get better joint
                  representations for classification.</li>
                <li> I proved the complementarity between data from two modalities. </li>
                <li> I studied the application of machine learning methods on small and uneven datasets.</li>
                <li> Cooperated with SYSU Cancer Center (<a href="https://www.sysucc.org.cn/"
                    target="_blank"><u>SYSUCC</u></a>).
              </ul>
            </li>
            <br>
          </ul>

          <div class="col-md-12"><br></div>

          <h4 style="text-align: center">Artificial Intelligence in Industry</h4>
          <ul>
            <li> <b>Deep discriminative feature learning on concrete surface images. [Jul. 2021 ~ Sep.
                2021] </b><br>
              Machine Perception Laboratory, SYSU, Guangzhou, China<br>
              <div class="col-md-12"><br></div>
              <div class="col-md-12">
                <div class="col-md-7"><img class="img" src="imgs/crack_res_1.jpg" width="500" height="120"
                    style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
                <div class="col-md-3"><img class="img" src="imgs/crack.jpg" width="220" height="120"
                    style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
              </div>
              <div class="col-md-12"><br></div>
              My contributions:
              <ul>
                <li> I participated in researching a novel end-to-end framework named Deep Discriminative Feature Learning (DDFL) based on Collective Matrix Factorization (CMF) and Vision Transformer (ViT) to extract and select discriminative features of crack images.</li>
                <li> The learning framework integrates the deep feature learning and feature selection so that more discriminative representation can be learned for crack classification.</li>
                <li> The article “Deep Discriminative Feature Learning for Concrete Surface Damage Classification” is submitted to IEEE TII.</li>
              </ul>
            </li>

            <div class="col-md-12"><br></div>

            <li> <b>Smart balanced delivery task scheduling. [Jul. 2021 ~ Aug. 2021] </b><br>
              Machine Perception Laboratory, SYSU, Guangzhou, China<br>
              <div class="col-md-12"><br></div>
              <div class="col-md-12">
                <div class="col-md-3"><img class="img" src="imgs/gcn_res_1.jpg" width="200" height="120"
                    style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
                <div class="col-md-3"><img class="img" src="imgs/gcn_res_2.jpg" width="200" height="120"
                    style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
                <div class="col-md-4"><img class="img" src="imgs/gcn_res_3.jpg" width="260" height="120"
                    style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
              </div>
              <div class="col-md-12"><br></div>
              My contributions:
              <ul>
                <li> I optimized one of the proposed algorithms by reducing loops and superimpose distance and time matrices, making
                  the computational complexity become 1/2 of the original method.</li> 
                <li> I re-implemented a baseline method <a href="https://github.com/wang-rq/GCN-NPEC"><u>[Code: GCN-NPEC]</u></a>. </li>
                <li> The results are expected to be published in Dec. 2021. </li>
              </ul>
            </li>



          </ul>
          </li>
          <br>


        </div>


        <!-- Teaching -->
        <div class="col-md-10">
          <h2 id="Teaching" style="font-family: Philosopher, sans-serif;">Teaching</h2>
          I have given two lectures for graduate students in the deep learning course offered by our laboratory in May
          2021.
          The two lectures are about VAE (Variational AutoEncoder) and GAN (Generative Adversarial Nets) respectively.
          <div class="col-md-12"><br></div>
          <div class="col-md-12">
            <div class="col-md-3"><img class="img" src="imgs/vae.jpg" width="150" height="100"
                style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
            <div class="col-md-3"><img class="img" src="imgs/gan.jpg" width="150" height="100"
                style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
          </div>
          <div class="col-md-12"><br></div>
          <br>
          My slides and prevues are as follows.
          <ul>
            <li>VAE: <a href="files/VAE_wrq.pdf" target="_blank"> <u>[Slide_VAE]</u></a>, <a
                href="https://www.bilibili.com/video/BV16f4y1N7ck" target="_blank"> <u>[Prevue_VAE]</u></a></li>
            <li>GAN: <a href="files/GAN_wrq.pdf" target="_blank"> <u>[Slide_GAN]</u></a>, <a
                href="https://www.bilibili.com/video/BV1kP4y1p7hQ" target="_blank"> <u>[Prevue_GAN]</u></a></li>
          </ul>
        </div>




        <!-- Hobbies -->
        <div class="col-md-10">
          <h2 id="Hobbies" style="font-family: Philosopher, sans-serif;">Hobbies</h2>
          <div class="col-md-12">
            <div class="col-md-1"><img class="img" src="imgs/sport2.jpg" width="25" height="25"
                style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
            <div class="col-md-1"><img class="img" src="imgs/sport3.jpg" width="25" height="25"
                style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
            <div class="col-md-1"><img class="img" src="imgs/sport1.jpg" width="25" height="25"
              style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
            <div class="col-md-1"><img class="img" src="imgs/sport4.jpg" width="25" height="25"
              style="box-shadow: 4px 4px 8px #888" alt="Spotlight_vd"></div>
          </div>
          <div class="col-md-12"><br></div>
          I like and do well in many sports.
          I have won gold medals in the long jump and a bronze medal in the long-distance running at the school games.
          Also, as one of the team members, I won the champion of the student union basketball competition.
          In addition, I entered the top 16 in the university table tennis competition.
          I am looking for more friends who have the same hobbies as me.
          If you like these sports, please contact me and we can exercise together!

          
        </div>

      </div>

    </div>
    <!-- /.container -->

    <!-- Other people may like it too! -->
    <a style="color:#b5bec9;font-size:0.8em; float:right;"
      href="https://github.com/mavroudisv/plain-academic">Template</a>

</body>

</html>